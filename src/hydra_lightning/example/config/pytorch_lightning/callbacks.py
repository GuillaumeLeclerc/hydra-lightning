# Autogenerated by configen, do not edit.
# If encountering an error, please file an issue @
# https://github.com/romesco/hydra-lightning 
# fmt: off
# isort: skip_file
# flake8: noqa
# Hydra + Lightning:

from dataclasses import dataclass, field
from builtins import dict
from omegaconf import MISSING
from typing import Optional


@dataclass
class EarlyStoppingConf:
    _target_: str = "pytorch_lightning.callbacks.EarlyStopping"
    monitor: str = "val_loss"
    min_delta: float = 0.0
    patience: int = 3
    verbose: bool = False
    mode: str = "auto"
    strict: bool = True


@dataclass
class GradientAccumulationSchedulerConf:
    _target_: str = "pytorch_lightning.callbacks.GradientAccumulationScheduler"
    scheduling: dict = MISSING


@dataclass
class ModelCheckpointConf:
    _target_: str = "pytorch_lightning.callbacks.ModelCheckpoint"
    filepath: Optional[str] = None
    monitor: str = "val_loss"
    verbose: bool = False
    save_last: bool = False
    save_top_k: int = 1
    save_weights_only: bool = False
    mode: str = "auto"
    period: int = 1
    prefix: str = ""


@dataclass
class ProgressBarConf:
    _target_: str = "pytorch_lightning.callbacks.ProgressBar"
    refresh_rate: int = 1
    process_position: int = 0
